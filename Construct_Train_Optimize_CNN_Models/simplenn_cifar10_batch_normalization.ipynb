{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tinayiluo0322/Computer-Engineering-Machine-Learning-and-Deep-Neural-Nets-Projects/blob/main/Construct_Train_Optimize_CNN_Models/simplenn_cifar10_batch_normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHU0uE10-zfR"
      },
      "source": [
        "# Optimizing SimpleNN on CIFAR-10\n",
        "\n",
        "#### Luopeiwen Yi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT2V-hEjUgCL",
        "outputId": "ee093447-a98a-4823-9c8f-7d417d7e1a64"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "6c_9k29BVqpd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this to the absolute path where dataset.py and utils.py are stored\n",
        "CODE_PATH = \"/content/drive/MyDrive/CNN_hw\"\n",
        "\n",
        "# Add this path to sys.path so Python can find it\n",
        "sys.path.append(CODE_PATH)\n",
        "\n",
        "# Check if Colab can see the files\n",
        "print(\"Files in directory:\", os.listdir(CODE_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y93THHD5Ul8F",
        "outputId": "6b08624d-f7d6-482a-90bf-edf370d80df5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in directory: ['sample_predictions.csv', 'save_test_predictions.ipynb', '__pycache__', 'tools', 'simplenn-cifar10.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5hTIizt-zfS"
      },
      "source": [
        "# Optimization 2: Batch Normalization\n",
        "\n",
        "## Step 1: Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TwB63cqB-zfS"
      },
      "outputs": [],
      "source": [
        "# import necessary dependencies\n",
        "import argparse\n",
        "import os, sys\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the SimpleNN mode;\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, 5)\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
        "        self.fc1   = nn.Linear(16*6*6, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "KEeDkc96E0L9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LjnAHdxy-zfT"
      },
      "outputs": [],
      "source": [
        "# Define SimpleNN with batch normalization\n",
        "class SimpleNN_BN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN_BN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, 5)\n",
        "        self.bn1 = nn.BatchNorm2d(8)  # BN Layer after conv1\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
        "        self.bn2 = nn.BatchNorm2d(16)  # BN Layer after conv2\n",
        "        self.fc1   = nn.Linear(16 * 6 * 6, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))  # Apply BN before activation\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2dWCG-f-zfT"
      },
      "source": [
        "### Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the SimpleNN model\n",
        "model = SimpleNN_BN()\n",
        "\n",
        "# Create a dummy input tensor with the same shape as CIFAR-10 images (batch_size=1, channels=3, height=32, width=32)\n",
        "dummy_input = torch.randn(1, 3, 32, 32)  # Shape: (1, 3, 32, 32)\n",
        "\n",
        "# Pass the dummy input through the model\n",
        "output = model(dummy_input)\n",
        "\n",
        "# Check the output shape\n",
        "print(f\"Output shape: {output.shape}\")  # Should be (1, 10) since we have 10 classes\n",
        "\n",
        "# Count total number of parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRsa5x3SMwRN",
        "outputId": "40e23b20-ed87-4d94-8ba4-ba4c39e3597e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 10])\n",
            "Total number of parameters: 82078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "# Set device to GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the SimpleNN model and move it to the selected device\n",
        "model = SimpleNN_BN().to(device)\n",
        "\n",
        "# Create a dummy input tensor and move it to the same device as the model\n",
        "dummy_input = torch.randn(1, 3, 32, 32).to(device)  # Ensure input is on the same device\n",
        "\n",
        "# Pass the dummy input through the model\n",
        "output = model(dummy_input)\n",
        "\n",
        "# Check the output shape\n",
        "print(f\"Output shape: {output.shape}\")  # Should be (1, 10) since we have 10 classes\n",
        "\n",
        "# Count total number of parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")\n",
        "\n",
        "# Print model summary (Ensure model is on the correct device)\n",
        "summary(model, (3, 32, 32), device=device.type)  # Specify the device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNgO5dK7gbv7",
        "outputId": "ff68d82f-ce39-43ec-be96-2e4b756872e2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Output shape: torch.Size([1, 10])\n",
            "Total number of parameters: 82078\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]             608\n",
            "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
            "            Conv2d-3           [-1, 16, 12, 12]           1,168\n",
            "       BatchNorm2d-4           [-1, 16, 12, 12]              32\n",
            "            Linear-5                  [-1, 120]          69,240\n",
            "            Linear-6                   [-1, 84]          10,164\n",
            "            Linear-7                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 82,078\n",
            "Trainable params: 82,078\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.13\n",
            "Params size (MB): 0.31\n",
            "Estimated Total Size (MB): 0.46\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX9zqVZk-zfT"
      },
      "source": [
        "## Step 1: Set up preprocessing functions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Data augmentation for training set\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  # Random cropping\n",
        "    transforms.RandomHorizontalFlip(),  # Random flipping\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))  # Normalize\n",
        "])\n",
        "\n",
        "# No data augmentation for validation set\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
        "])"
      ],
      "metadata": {
        "id": "ydUJrZOwOcFz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ToTensor(): Converts PIL images to PyTorch tensors so they can be used in deep learning models.\n",
        "\n",
        "Normalize(mean, std): Standardizes pixel values to a mean of (0.4914, 0.4822, 0.4465) and std of (0.2023, 0.1994, 0.2010), helping the model converge faster.\n"
      ],
      "metadata": {
        "id": "MCNib8fBOoHv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHl6i1gP-zfT"
      },
      "source": [
        "## Step 2: Set up dataset and dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do NOT change these\n",
        "from tools.dataset import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# A few arguments, do NOT change these\n",
        "DATA_ROOT = \"./data\"\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VAL_BATCH_SIZE = 100\n",
        "\n",
        "# Construct dataset\n",
        "train_set = CIFAR10(\n",
        "    root=DATA_ROOT,\n",
        "    mode='train',\n",
        "    download=True,\n",
        "    transform=transform_train  # Apply training preprocessing\n",
        ")\n",
        "\n",
        "val_set = CIFAR10(\n",
        "    root=DATA_ROOT,\n",
        "    mode='val',\n",
        "    download=True,\n",
        "    transform=transform_val  # Apply validation preprocessing\n",
        ")\n",
        "\n",
        "# Construct dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=TRAIN_BATCH_SIZE,  # Use predefined batch size\n",
        "    shuffle=True,  # Shuffle training data for randomness\n",
        "    num_workers=4  # Speed up data loading\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_set,\n",
        "    batch_size=VAL_BATCH_SIZE,  # Use predefined batch size\n",
        "    shuffle=False,  # No need to shuffle validation data\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Sanity Check: Print dataset sizes\n",
        "print(f\"Train dataset size: {len(train_set)} images\")\n",
        "print(f\"Validation dataset size: {len(val_set)} images\")\n",
        "\n",
        "# Check a single batch\n",
        "sample_batch, sample_labels = next(iter(train_loader))\n",
        "print(f\"Sample batch shape: {sample_batch.shape}, Labels shape: {sample_labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElpvReM0QMta",
        "outputId": "8dde688e-87db-45c5-fbcb-577029d389dc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.dropbox.com/s/s8orza214q45b23/cifar10_trainval_F22.zip?dl=1 to ./data/cifar10_trainval_F22.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "141746176it [00:10, 13623064.13it/s]                               \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar10_trainval_F22.zip to ./data\n",
            "Files already downloaded and verified\n",
            "Using downloaded and verified file: ./data/cifar10_trainval_F22.zip\n",
            "Extracting ./data/cifar10_trainval_F22.zip to ./data\n",
            "Files already downloaded and verified\n",
            "Train dataset size: 45000 images\n",
            "Validation dataset size: 5000 images\n",
            "Sample batch shape: torch.Size([128, 3, 32, 32]), Labels shape: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load one batch of training data\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# Function to unnormalize and display images\n",
        "def imshow(img):\n",
        "    img = img.numpy().transpose((1, 2, 0))  # Convert to HWC format\n",
        "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
        "    std = np.array([0.2023, 0.1994, 0.2010])\n",
        "    img = img * std + mean  # Unnormalize\n",
        "    img = np.clip(img, 0, 1)\n",
        "    plt.imshow(img)\n",
        "\n",
        "# Plot some augmented images\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15,3))\n",
        "for i in range(5):\n",
        "    imshow(images[i])\n",
        "    axes[i].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "9koobFWv6ekY",
        "outputId": "b41f7984-08f8-4bb5-dd0d-de690450ffc8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WknGJMp1-zfU"
      },
      "source": [
        "## Step 4: Set up the loss function and optimizer\n",
        "Loss function/objective function is used to provide \"feedback\" for the neural networks. Typically, we use multi-class cross-entropy as the loss function for classification models. As for the optimizer, we will use SGD with momentum."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Hyperparameters (Do NOT change)\n",
        "INITIAL_LR = 0.01  # Initial learning rate\n",
        "MOMENTUM = 0.9  # Momentum for optimizer\n",
        "REG = 1e-4  # L2 regularization (weight decay)\n",
        "\n",
        "# Create loss function (Cross-Entropy Loss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Add optimizer (SGD with Momentum and L2 Regularization)\n",
        "optimizer = optim.SGD(\n",
        "    model.parameters(),  # Optimizing model parameters\n",
        "    lr=INITIAL_LR,  # Learning rate\n",
        "    momentum=MOMENTUM,  # Momentum factor\n",
        "    weight_decay=REG  # L2 regularization\n",
        ")\n",
        "\n",
        "# Sanity check: Print optimizer details\n",
        "print(optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7qWQMaSie7z",
        "outputId": "19bd17f4-2a02-4b0c-8fa7-9abc8331639a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0001\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13GUGlfU-zfU"
      },
      "source": [
        "## Step 5: Start the training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "def train_model(model, optimizer, filename, epochs=30):\n",
        "    \"\"\" Train the model and save the best checkpoint \"\"\"\n",
        "\n",
        "    CHECKPOINT_FOLDER = \"./saved_model_dev\"\n",
        "    best_val_acc = 0\n",
        "\n",
        "    # Ensure model is on the correct device\n",
        "    model.to(device)\n",
        "\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    initial_loss = 0\n",
        "    total_examples = 0\n",
        "    correct_examples = 0\n",
        "\n",
        "    with torch.no_grad():  # No gradient calculation\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            # Copy inputs and targets to the device\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass: compute the output\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, targets)\n",
        "            initial_loss += loss.item()\n",
        "\n",
        "            # Compute accuracy before training\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_examples += (predicted == targets).sum().item()\n",
        "            total_examples += targets.size(0)\n",
        "\n",
        "            # Only calculate on a small subset (e.g., 1 batch)\n",
        "            if batch_idx == 0:\n",
        "                break\n",
        "\n",
        "    # Compute initial average loss and accuracy\n",
        "    initial_loss /= (batch_idx + 1)\n",
        "    initial_acc = correct_examples / total_examples\n",
        "    print(f\"Initial loss before training: {initial_loss:.4f}, Initial accuracy: {initial_acc:.4f}\")\n",
        "\n",
        "\n",
        "    print(f\"==> Training {filename} model\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        print(f\"Epoch {i}:\")\n",
        "\n",
        "        total_examples = 0\n",
        "        correct_examples = 0\n",
        "        train_loss = 0\n",
        "\n",
        "        # Train loop\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Zero gradients & backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_examples += (predicted == targets).sum().item()\n",
        "            total_examples += targets.size(0)\n",
        "\n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "        avg_acc = correct_examples / total_examples\n",
        "        print(f\"Training loss: {avg_loss:.4f}, Training accuracy: {avg_acc:.4f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        total_examples = 0\n",
        "        correct_examples = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_examples += (predicted == targets).sum().item()\n",
        "                total_examples += targets.size(0)\n",
        "\n",
        "        avg_loss = val_loss / len(val_loader)\n",
        "        avg_acc = correct_examples / total_examples\n",
        "        print(f\"Validation loss: {avg_loss:.4f}, Validation accuracy: {avg_acc:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if avg_acc > best_val_acc:\n",
        "            best_val_acc = avg_acc\n",
        "            if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "                os.makedirs(CHECKPOINT_FOLDER)\n",
        "            print(f\"Saving best model for {filename}...\")\n",
        "            torch.save({'state_dict': model.state_dict()}, os.path.join(CHECKPOINT_FOLDER, filename))\n",
        "\n",
        "        print('')\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"==> Training finished for {filename}! Best validation accuracy: {best_val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "fXnc90UYGne3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Comparison with default learning rate"
      ],
      "metadata": {
        "id": "L0WZtXErIswV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SimpleNN Without BN (Low Learning Rate)\n",
        "model_no_bn = SimpleNN().to(device)\n",
        "optimizer_no_bn = torch.optim.SGD(model_no_bn.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "train_model(model_no_bn, optimizer_no_bn, \"model_no_bn.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ3EFl6yLgVJ",
        "outputId": "e770fc9f-d1b9-49db-a50a-76c9eac96a98"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss before training: 2.3071, Initial accuracy: 0.1016\n",
            "==> Training model_no_bn.pth model\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 1.9697, Training accuracy: 0.2726\n",
            "Validation loss: 1.6067, Validation accuracy: 0.4048\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.5879, Training accuracy: 0.4167\n",
            "Validation loss: 1.4237, Validation accuracy: 0.4788\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.4589, Training accuracy: 0.4708\n",
            "Validation loss: 1.3468, Validation accuracy: 0.5250\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.3691, Training accuracy: 0.5038\n",
            "Validation loss: 1.2583, Validation accuracy: 0.5590\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.3050, Training accuracy: 0.5305\n",
            "Validation loss: 1.2001, Validation accuracy: 0.5740\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.2414, Training accuracy: 0.5577\n",
            "Validation loss: 1.1600, Validation accuracy: 0.5860\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.1966, Training accuracy: 0.5751\n",
            "Validation loss: 1.1323, Validation accuracy: 0.6076\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.1654, Training accuracy: 0.5879\n",
            "Validation loss: 1.1108, Validation accuracy: 0.6150\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.1349, Training accuracy: 0.5975\n",
            "Validation loss: 1.1168, Validation accuracy: 0.5936\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.1037, Training accuracy: 0.6081\n",
            "Validation loss: 1.0224, Validation accuracy: 0.6402\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 10:\n",
            "Training loss: 1.0808, Training accuracy: 0.6173\n",
            "Validation loss: 1.0593, Validation accuracy: 0.6240\n",
            "\n",
            "Epoch 11:\n",
            "Training loss: 1.0598, Training accuracy: 0.6212\n",
            "Validation loss: 1.0696, Validation accuracy: 0.6130\n",
            "\n",
            "Epoch 12:\n",
            "Training loss: 1.0377, Training accuracy: 0.6348\n",
            "Validation loss: 0.9807, Validation accuracy: 0.6532\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 13:\n",
            "Training loss: 1.0258, Training accuracy: 0.6393\n",
            "Validation loss: 1.0070, Validation accuracy: 0.6534\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 14:\n",
            "Training loss: 1.0141, Training accuracy: 0.6426\n",
            "Validation loss: 0.9893, Validation accuracy: 0.6554\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 15:\n",
            "Training loss: 0.9978, Training accuracy: 0.6490\n",
            "Validation loss: 0.9753, Validation accuracy: 0.6582\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 16:\n",
            "Training loss: 0.9898, Training accuracy: 0.6525\n",
            "Validation loss: 0.9476, Validation accuracy: 0.6676\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 17:\n",
            "Training loss: 0.9761, Training accuracy: 0.6576\n",
            "Validation loss: 0.9277, Validation accuracy: 0.6790\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 18:\n",
            "Training loss: 0.9627, Training accuracy: 0.6606\n",
            "Validation loss: 0.8861, Validation accuracy: 0.6908\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 19:\n",
            "Training loss: 0.9637, Training accuracy: 0.6616\n",
            "Validation loss: 0.8853, Validation accuracy: 0.6904\n",
            "\n",
            "Epoch 20:\n",
            "Training loss: 0.9465, Training accuracy: 0.6679\n",
            "Validation loss: 0.9021, Validation accuracy: 0.6788\n",
            "\n",
            "Epoch 21:\n",
            "Training loss: 0.9350, Training accuracy: 0.6720\n",
            "Validation loss: 0.9160, Validation accuracy: 0.6796\n",
            "\n",
            "Epoch 22:\n",
            "Training loss: 0.9283, Training accuracy: 0.6728\n",
            "Validation loss: 0.8977, Validation accuracy: 0.6826\n",
            "\n",
            "Epoch 23:\n",
            "Training loss: 0.9163, Training accuracy: 0.6796\n",
            "Validation loss: 0.9242, Validation accuracy: 0.6820\n",
            "\n",
            "Epoch 24:\n",
            "Training loss: 0.9047, Training accuracy: 0.6804\n",
            "Validation loss: 0.9014, Validation accuracy: 0.6888\n",
            "\n",
            "Epoch 25:\n",
            "Training loss: 0.9060, Training accuracy: 0.6824\n",
            "Validation loss: 0.9054, Validation accuracy: 0.6808\n",
            "\n",
            "Epoch 26:\n",
            "Training loss: 0.9003, Training accuracy: 0.6834\n",
            "Validation loss: 0.8529, Validation accuracy: 0.7018\n",
            "Saving best model for model_no_bn.pth...\n",
            "\n",
            "Epoch 27:\n",
            "Training loss: 0.8916, Training accuracy: 0.6880\n",
            "Validation loss: 0.8671, Validation accuracy: 0.6968\n",
            "\n",
            "Epoch 28:\n",
            "Training loss: 0.8867, Training accuracy: 0.6861\n",
            "Validation loss: 0.8663, Validation accuracy: 0.6988\n",
            "\n",
            "Epoch 29:\n",
            "Training loss: 0.8751, Training accuracy: 0.6951\n",
            "Validation loss: 0.9025, Validation accuracy: 0.6798\n",
            "\n",
            "==================================================\n",
            "==> Training finished for model_no_bn.pth! Best validation accuracy: 0.7018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SimpleNN With BN (Low Learning Rate)\n",
        "model_bn = SimpleNN_BN().to(device)\n",
        "optimizer_bn = torch.optim.SGD(model_bn.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "train_model(model_bn, optimizer_bn, \"model_with_bn.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHjgn5wMLo61",
        "outputId": "b7aa0fcd-7dda-4ab9-8aba-272d4f9cf0a1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss before training: 2.2980, Initial accuracy: 0.1016\n",
            "==> Training model_with_bn.pth model\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 1.7765, Training accuracy: 0.3409\n",
            "Validation loss: 1.4518, Validation accuracy: 0.4780\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.4321, Training accuracy: 0.4757\n",
            "Validation loss: 1.2983, Validation accuracy: 0.5404\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.3128, Training accuracy: 0.5295\n",
            "Validation loss: 1.2478, Validation accuracy: 0.5600\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.2309, Training accuracy: 0.5578\n",
            "Validation loss: 1.1611, Validation accuracy: 0.5962\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.1807, Training accuracy: 0.5766\n",
            "Validation loss: 1.1230, Validation accuracy: 0.6018\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.1421, Training accuracy: 0.5933\n",
            "Validation loss: 1.0662, Validation accuracy: 0.6266\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.1107, Training accuracy: 0.6041\n",
            "Validation loss: 1.1573, Validation accuracy: 0.5974\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.0863, Training accuracy: 0.6120\n",
            "Validation loss: 1.0546, Validation accuracy: 0.6300\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.0580, Training accuracy: 0.6243\n",
            "Validation loss: 1.0400, Validation accuracy: 0.6310\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.0408, Training accuracy: 0.6318\n",
            "Validation loss: 1.0118, Validation accuracy: 0.6446\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 10:\n",
            "Training loss: 1.0309, Training accuracy: 0.6360\n",
            "Validation loss: 1.0136, Validation accuracy: 0.6450\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 11:\n",
            "Training loss: 1.0054, Training accuracy: 0.6442\n",
            "Validation loss: 0.9795, Validation accuracy: 0.6596\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 12:\n",
            "Training loss: 0.9998, Training accuracy: 0.6458\n",
            "Validation loss: 0.9671, Validation accuracy: 0.6620\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 13:\n",
            "Training loss: 0.9803, Training accuracy: 0.6526\n",
            "Validation loss: 0.9842, Validation accuracy: 0.6498\n",
            "\n",
            "Epoch 14:\n",
            "Training loss: 0.9810, Training accuracy: 0.6537\n",
            "Validation loss: 0.9399, Validation accuracy: 0.6646\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 15:\n",
            "Training loss: 0.9624, Training accuracy: 0.6581\n",
            "Validation loss: 0.9336, Validation accuracy: 0.6796\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 16:\n",
            "Training loss: 0.9547, Training accuracy: 0.6610\n",
            "Validation loss: 0.9615, Validation accuracy: 0.6682\n",
            "\n",
            "Epoch 17:\n",
            "Training loss: 0.9436, Training accuracy: 0.6659\n",
            "Validation loss: 0.9114, Validation accuracy: 0.6824\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 18:\n",
            "Training loss: 0.9304, Training accuracy: 0.6698\n",
            "Validation loss: 0.9333, Validation accuracy: 0.6708\n",
            "\n",
            "Epoch 19:\n",
            "Training loss: 0.9230, Training accuracy: 0.6752\n",
            "Validation loss: 0.9237, Validation accuracy: 0.6802\n",
            "\n",
            "Epoch 20:\n",
            "Training loss: 0.9176, Training accuracy: 0.6738\n",
            "Validation loss: 0.9485, Validation accuracy: 0.6688\n",
            "\n",
            "Epoch 21:\n",
            "Training loss: 0.9116, Training accuracy: 0.6793\n",
            "Validation loss: 0.9363, Validation accuracy: 0.6746\n",
            "\n",
            "Epoch 22:\n",
            "Training loss: 0.9082, Training accuracy: 0.6787\n",
            "Validation loss: 0.9011, Validation accuracy: 0.6884\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 23:\n",
            "Training loss: 0.8999, Training accuracy: 0.6818\n",
            "Validation loss: 0.8814, Validation accuracy: 0.6898\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 24:\n",
            "Training loss: 0.8880, Training accuracy: 0.6851\n",
            "Validation loss: 0.9145, Validation accuracy: 0.6782\n",
            "\n",
            "Epoch 25:\n",
            "Training loss: 0.8830, Training accuracy: 0.6872\n",
            "Validation loss: 0.8642, Validation accuracy: 0.6966\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 26:\n",
            "Training loss: 0.8761, Training accuracy: 0.6926\n",
            "Validation loss: 0.8537, Validation accuracy: 0.7064\n",
            "Saving best model for model_with_bn.pth...\n",
            "\n",
            "Epoch 27:\n",
            "Training loss: 0.8787, Training accuracy: 0.6890\n",
            "Validation loss: 0.8585, Validation accuracy: 0.6994\n",
            "\n",
            "Epoch 28:\n",
            "Training loss: 0.8703, Training accuracy: 0.6929\n",
            "Validation loss: 0.8761, Validation accuracy: 0.6916\n",
            "\n",
            "Epoch 29:\n",
            "Training loss: 0.8669, Training accuracy: 0.6958\n",
            "Validation loss: 0.8510, Validation accuracy: 0.7026\n",
            "\n",
            "==================================================\n",
            "==> Training finished for model_with_bn.pth! Best validation accuracy: 0.7064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Comparison with higher learning rate"
      ],
      "metadata": {
        "id": "RC00xOtzJQ1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SimpleNN Without BN (High Learning Rate)\n",
        "model_no_bn_high_rate = SimpleNN().to(device)\n",
        "optimizer_no_bn_high_rate = torch.optim.SGD(model_no_bn_high_rate.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "train_model(model_no_bn_high_rate, optimizer_no_bn_high_rate, \"model_no_bn_high_rate.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxysPrxfLk5R",
        "outputId": "835590fe-0236-40a5-9323-f9bc1bb67f44"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss before training: 2.2965, Initial accuracy: 0.0859\n",
            "==> Training model_no_bn_high_rate.pth model\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 1.9215, Training accuracy: 0.2828\n",
            "Validation loss: 1.6466, Validation accuracy: 0.3988\n",
            "Saving best model for model_no_bn_high_rate.pth...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.7480, Training accuracy: 0.3532\n",
            "Validation loss: 1.6402, Validation accuracy: 0.3958\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.7023, Training accuracy: 0.3758\n",
            "Validation loss: 1.6052, Validation accuracy: 0.4108\n",
            "Saving best model for model_no_bn_high_rate.pth...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.6714, Training accuracy: 0.3882\n",
            "Validation loss: 1.5978, Validation accuracy: 0.4222\n",
            "Saving best model for model_no_bn_high_rate.pth...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.6552, Training accuracy: 0.3985\n",
            "Validation loss: 1.5550, Validation accuracy: 0.4276\n",
            "Saving best model for model_no_bn_high_rate.pth...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.6115, Training accuracy: 0.4194\n",
            "Validation loss: 1.5358, Validation accuracy: 0.4500\n",
            "Saving best model for model_no_bn_high_rate.pth...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.6200, Training accuracy: 0.4172\n",
            "Validation loss: 1.5028, Validation accuracy: 0.4552\n",
            "Saving best model for model_no_bn_high_rate.pth...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.5755, Training accuracy: 0.4322\n",
            "Validation loss: 1.4946, Validation accuracy: 0.4560\n",
            "Saving best model for model_no_bn_high_rate.pth...\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.5936, Training accuracy: 0.4290\n",
            "Validation loss: 1.5164, Validation accuracy: 0.4746\n",
            "Saving best model for model_no_bn_high_rate.pth...\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.6002, Training accuracy: 0.4311\n",
            "Validation loss: 1.5136, Validation accuracy: 0.4806\n",
            "Saving best model for model_no_bn_high_rate.pth...\n",
            "\n",
            "Epoch 10:\n",
            "Training loss: 1.5889, Training accuracy: 0.4338\n",
            "Validation loss: 1.5372, Validation accuracy: 0.4558\n",
            "\n",
            "Epoch 11:\n",
            "Training loss: 1.5980, Training accuracy: 0.4332\n",
            "Validation loss: 1.4820, Validation accuracy: 0.4980\n",
            "Saving best model for model_no_bn_high_rate.pth...\n",
            "\n",
            "Epoch 12:\n",
            "Training loss: 1.5785, Training accuracy: 0.4415\n",
            "Validation loss: 1.5610, Validation accuracy: 0.4374\n",
            "\n",
            "Epoch 13:\n",
            "Training loss: 1.5872, Training accuracy: 0.4369\n",
            "Validation loss: 1.5033, Validation accuracy: 0.4660\n",
            "\n",
            "Epoch 14:\n",
            "Training loss: 1.5787, Training accuracy: 0.4441\n",
            "Validation loss: 1.4643, Validation accuracy: 0.4908\n",
            "\n",
            "Epoch 15:\n",
            "Training loss: 1.5757, Training accuracy: 0.4430\n",
            "Validation loss: 1.5745, Validation accuracy: 0.4476\n",
            "\n",
            "Epoch 16:\n",
            "Training loss: 1.5675, Training accuracy: 0.4506\n",
            "Validation loss: 1.4626, Validation accuracy: 0.4734\n",
            "\n",
            "Epoch 17:\n",
            "Training loss: 1.5860, Training accuracy: 0.4451\n",
            "Validation loss: 1.5068, Validation accuracy: 0.4684\n",
            "\n",
            "Epoch 18:\n",
            "Training loss: 1.5595, Training accuracy: 0.4525\n",
            "Validation loss: 1.5902, Validation accuracy: 0.4582\n",
            "\n",
            "Epoch 19:\n",
            "Training loss: 1.5719, Training accuracy: 0.4493\n",
            "Validation loss: 1.5138, Validation accuracy: 0.4710\n",
            "\n",
            "Epoch 20:\n",
            "Training loss: 1.5599, Training accuracy: 0.4566\n",
            "Validation loss: 1.4833, Validation accuracy: 0.4772\n",
            "\n",
            "Epoch 21:\n",
            "Training loss: 1.5819, Training accuracy: 0.4448\n",
            "Validation loss: 1.5302, Validation accuracy: 0.4736\n",
            "\n",
            "Epoch 22:\n",
            "Training loss: 1.5630, Training accuracy: 0.4545\n",
            "Validation loss: 1.5033, Validation accuracy: 0.4886\n",
            "\n",
            "Epoch 23:\n",
            "Training loss: 1.5600, Training accuracy: 0.4608\n",
            "Validation loss: 1.5086, Validation accuracy: 0.4782\n",
            "\n",
            "Epoch 24:\n",
            "Training loss: 1.5752, Training accuracy: 0.4517\n",
            "Validation loss: 1.4646, Validation accuracy: 0.4958\n",
            "\n",
            "Epoch 25:\n",
            "Training loss: 1.5613, Training accuracy: 0.4624\n",
            "Validation loss: 1.5217, Validation accuracy: 0.4804\n",
            "\n",
            "Epoch 26:\n",
            "Training loss: 1.5554, Training accuracy: 0.4590\n",
            "Validation loss: 1.5311, Validation accuracy: 0.4964\n",
            "\n",
            "Epoch 27:\n",
            "Training loss: 1.5656, Training accuracy: 0.4550\n",
            "Validation loss: 1.6277, Validation accuracy: 0.4500\n",
            "\n",
            "Epoch 28:\n",
            "Training loss: 1.5520, Training accuracy: 0.4597\n",
            "Validation loss: 1.5388, Validation accuracy: 0.4622\n",
            "\n",
            "Epoch 29:\n",
            "Training loss: 1.5518, Training accuracy: 0.4602\n",
            "Validation loss: 1.4993, Validation accuracy: 0.4718\n",
            "\n",
            "==================================================\n",
            "==> Training finished for model_no_bn_high_rate.pth! Best validation accuracy: 0.4980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SimpleNN With BN (High Learning Rate)\n",
        "model_bn_high_rate = SimpleNN_BN().to(device)\n",
        "optimizer_bn_high_rate = torch.optim.SGD(model_bn_high_rate.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "train_model(model_bn_high_rate, optimizer_bn_high_rate, \"model_with_bn_high_rate.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t60PYdq2Lqhp",
        "outputId": "d5928c7e-2ebc-4344-d120-18764e227a0e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss before training: 2.3094, Initial accuracy: 0.0781\n",
            "==> Training model_with_bn_high_rate.pth model\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 1.7182, Training accuracy: 0.3588\n",
            "Validation loss: 1.4590, Validation accuracy: 0.4694\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.4654, Training accuracy: 0.4714\n",
            "Validation loss: 1.2791, Validation accuracy: 0.5318\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.3450, Training accuracy: 0.5226\n",
            "Validation loss: 1.3389, Validation accuracy: 0.5158\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.2885, Training accuracy: 0.5443\n",
            "Validation loss: 1.2339, Validation accuracy: 0.5614\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.2356, Training accuracy: 0.5655\n",
            "Validation loss: 1.1980, Validation accuracy: 0.5812\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.2011, Training accuracy: 0.5764\n",
            "Validation loss: 1.1567, Validation accuracy: 0.6052\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.1686, Training accuracy: 0.5894\n",
            "Validation loss: 1.0813, Validation accuracy: 0.6170\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.1486, Training accuracy: 0.5973\n",
            "Validation loss: 1.1155, Validation accuracy: 0.6060\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.1325, Training accuracy: 0.6016\n",
            "Validation loss: 1.0811, Validation accuracy: 0.6164\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.1229, Training accuracy: 0.6078\n",
            "Validation loss: 1.0477, Validation accuracy: 0.6286\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 10:\n",
            "Training loss: 1.1049, Training accuracy: 0.6152\n",
            "Validation loss: 1.0324, Validation accuracy: 0.6352\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 11:\n",
            "Training loss: 1.0876, Training accuracy: 0.6220\n",
            "Validation loss: 1.0924, Validation accuracy: 0.6208\n",
            "\n",
            "Epoch 12:\n",
            "Training loss: 1.0955, Training accuracy: 0.6178\n",
            "Validation loss: 1.1068, Validation accuracy: 0.6190\n",
            "\n",
            "Epoch 13:\n",
            "Training loss: 1.0804, Training accuracy: 0.6236\n",
            "Validation loss: 1.0735, Validation accuracy: 0.6288\n",
            "\n",
            "Epoch 14:\n",
            "Training loss: 1.0757, Training accuracy: 0.6257\n",
            "Validation loss: 1.0307, Validation accuracy: 0.6420\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 15:\n",
            "Training loss: 1.0634, Training accuracy: 0.6295\n",
            "Validation loss: 1.0711, Validation accuracy: 0.6268\n",
            "\n",
            "Epoch 16:\n",
            "Training loss: 1.0632, Training accuracy: 0.6262\n",
            "Validation loss: 1.0256, Validation accuracy: 0.6466\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 17:\n",
            "Training loss: 1.0512, Training accuracy: 0.6351\n",
            "Validation loss: 0.9764, Validation accuracy: 0.6572\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 18:\n",
            "Training loss: 1.0433, Training accuracy: 0.6392\n",
            "Validation loss: 0.9780, Validation accuracy: 0.6604\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 19:\n",
            "Training loss: 1.0416, Training accuracy: 0.6352\n",
            "Validation loss: 1.0141, Validation accuracy: 0.6470\n",
            "\n",
            "Epoch 20:\n",
            "Training loss: 1.0408, Training accuracy: 0.6349\n",
            "Validation loss: 1.0092, Validation accuracy: 0.6448\n",
            "\n",
            "Epoch 21:\n",
            "Training loss: 1.0394, Training accuracy: 0.6390\n",
            "Validation loss: 0.9956, Validation accuracy: 0.6566\n",
            "\n",
            "Epoch 22:\n",
            "Training loss: 1.0336, Training accuracy: 0.6404\n",
            "Validation loss: 0.9956, Validation accuracy: 0.6526\n",
            "\n",
            "Epoch 23:\n",
            "Training loss: 1.0318, Training accuracy: 0.6389\n",
            "Validation loss: 0.9433, Validation accuracy: 0.6736\n",
            "Saving best model for model_with_bn_high_rate.pth...\n",
            "\n",
            "Epoch 24:\n",
            "Training loss: 1.0210, Training accuracy: 0.6455\n",
            "Validation loss: 0.9591, Validation accuracy: 0.6704\n",
            "\n",
            "Epoch 25:\n",
            "Training loss: 1.0191, Training accuracy: 0.6463\n",
            "Validation loss: 0.9711, Validation accuracy: 0.6594\n",
            "\n",
            "Epoch 26:\n",
            "Training loss: 1.0241, Training accuracy: 0.6432\n",
            "Validation loss: 0.9796, Validation accuracy: 0.6598\n",
            "\n",
            "Epoch 27:\n",
            "Training loss: 1.0158, Training accuracy: 0.6467\n",
            "Validation loss: 0.9789, Validation accuracy: 0.6622\n",
            "\n",
            "Epoch 28:\n",
            "Training loss: 1.0144, Training accuracy: 0.6490\n",
            "Validation loss: 1.0100, Validation accuracy: 0.6488\n",
            "\n",
            "Epoch 29:\n",
            "Training loss: 1.0080, Training accuracy: 0.6499\n",
            "Validation loss: 0.9924, Validation accuracy: 0.6570\n",
            "\n",
            "==================================================\n",
            "==> Training finished for model_with_bn_high_rate.pth! Best validation accuracy: 0.6736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch normalization allows a larger learning rate"
      ],
      "metadata": {
        "id": "KaOMxSzzPKwq"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}